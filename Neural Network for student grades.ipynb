{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4fca1c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f84cde01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/dipam7/student-grade-prediction\n",
    "# P. Cortez and A. Silva. Using Data Mining to Predict Secondary School Student Performance. In A. Brito and J. Teixeira Eds., Proceedings of 5th FUture BUsiness TEChnology Conference (FUBUTEC 2008) pp. 5-12, Porto, Portugal, April, 2008, EUROSIS, ISBN 978-9077381-39-7.\n",
    "df = pd.read_csv('./student-mat.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b4329197",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.drop(columns=['school','address','Mjob','Fjob','reason'], inplace=True)\n",
    "for i in df.index:\n",
    "    df.loc[i,\"sex\"] = 0 if df.loc[i,\"sex\"] == \"F\" else 1\n",
    "    df.loc[i,\"famsize\"] = 0 if df.loc[i,\"famsize\"] == 'LT3' else 1\n",
    "    df.loc[i,'Pstatus'] = 0 if df.loc[i,'Pstatus'] == 'A' else 1\n",
    "    df.loc[i,'guardian'] = 0 if df.loc[i,'guardian'] == 'mother' else 1 if df.loc[i,'guardian'] == 'father' else 2\n",
    "    df.loc[i,\"schoolsup\"] = 0 if df.loc[i,\"schoolsup\"] == 'no' else 1\n",
    "    df.loc[i,\"famsup\"] = 0 if df.loc[i,\"famsup\"] == 'no' else 1\n",
    "    df.loc[i,\"paid\"] = 0 if df.loc[i,\"paid\"] == 'no' else 1\n",
    "    df.loc[i,\"activities\"] = 0 if df.loc[i,\"activities\"] == 'no' else 1\n",
    "    df.loc[i,\"nursery\"] = 0 if df.loc[i,\"nursery\"] == 'no' else 1\n",
    "    df.loc[i,\"higher\"] = 0 if df.loc[i,\"higher\"] == 'no' else 1\n",
    "    df.loc[i,\"internet\"] = 0 if df.loc[i,\"internet\"] == 'no' else 1\n",
    "    df.loc[i,\"romantic\"] = 0 if df.loc[i,\"romantic\"] == 'no' else 1\n",
    "# df = pd.get_dummies(df)\n",
    "\n",
    "out = np.where(df['G3'] > 13, 1, 0) # greater than 65% is passing\n",
    "inp = df.drop(['G3'], axis=1)\n",
    "\n",
    "# print(df.shape)\n",
    "# print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "56149596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(X_train, X_test, y_train, y_test, layers, learning_rate):\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=layers, solver=\"lbfgs\",\n",
    "                        learning_rate_init=learning_rate, max_iter=1000)\n",
    "    mlp.fit(X_train, y_train)\n",
    "    y_pred = mlp.predict(X_test)\n",
    "    \n",
    "#     # plot weights\n",
    "    plt.figure(figsize=(12, 6), dpi=80)\n",
    "    plt.scatter(inp.columns, mlp.coefs_[0])\n",
    "    plt.xticks(rotation = 45)\n",
    "    \n",
    "    print(f\"layers = {layers}, learning rate = {learning_rate}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"\\tTraining Accuracy = {mlp.score(X_train, y_train)}\")\n",
    "    print(f\"\\tTesting Accuracy = {mlp.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "685df6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers = (8, 8, 8), learning rate = 0.001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94        58\n",
      "           1       0.85      0.81      0.83        21\n",
      "\n",
      "    accuracy                           0.91        79\n",
      "   macro avg       0.89      0.88      0.88        79\n",
      "weighted avg       0.91      0.91      0.91        79\n",
      "\n",
      "\tTraining Accuracy = 1.0\n",
      "\tTesting Accuracy = 0.9113924050632911\n",
      "layers = (8, 8, 8), learning rate = 0.01\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.92        58\n",
      "           1       0.79      0.71      0.75        21\n",
      "\n",
      "    accuracy                           0.87        79\n",
      "   macro avg       0.84      0.82      0.83        79\n",
      "weighted avg       0.87      0.87      0.87        79\n",
      "\n",
      "\tTraining Accuracy = 1.0\n",
      "\tTesting Accuracy = 0.8734177215189873\n",
      "layers = (8, 8, 8), learning rate = 0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96        58\n",
      "           1       0.86      0.90      0.88        21\n",
      "\n",
      "    accuracy                           0.94        79\n",
      "   macro avg       0.91      0.93      0.92        79\n",
      "weighted avg       0.94      0.94      0.94        79\n",
      "\n",
      "\tTraining Accuracy = 0.9873417721518988\n",
      "\tTesting Accuracy = 0.9367088607594937\n",
      "layers = (8, 8, 8), learning rate = 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        58\n",
      "           1       0.89      0.81      0.85        21\n",
      "\n",
      "    accuracy                           0.92        79\n",
      "   macro avg       0.91      0.89      0.90        79\n",
      "weighted avg       0.92      0.92      0.92        79\n",
      "\n",
      "\tTraining Accuracy = 1.0\n",
      "\tTesting Accuracy = 0.9240506329113924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jtse0\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jtse0\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1c8ced59cd0>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(inp, out, test_size=.2)\n",
    "\n",
    "test(X_train, X_test, y_train, y_test, (8,8,8), .001)\n",
    "test(X_train, X_test, y_train, y_test, (8,8,8), .01)\n",
    "test(X_train, X_test, y_train, y_test, (8,8,8), .1)\n",
    "test(X_train, X_test, y_train, y_test, (8,8,8), 1)\n",
    "\n",
    "train_sizes, train_scores, test_scores, fit_times, score_times = learning_curve(\n",
    "    MLPClassifier((8,8,8), max_iter=1000), X_train, y_train, cv=5, return_times=True)\n",
    "plt.scatter(fit_times, test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8f963349",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jtse0\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers = 2, learning rate = 0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92        58\n",
      "           1       0.83      0.71      0.77        21\n",
      "\n",
      "    accuracy                           0.89        79\n",
      "   macro avg       0.87      0.83      0.85        79\n",
      "weighted avg       0.88      0.89      0.88        79\n",
      "\n",
      "\tTraining Accuracy = 0.9841772151898734\n",
      "\tTesting Accuracy = 0.8860759493670886\n",
      "layers = 8, learning rate = 0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96        58\n",
      "           1       0.94      0.81      0.87        21\n",
      "\n",
      "    accuracy                           0.94        79\n",
      "   macro avg       0.94      0.90      0.91        79\n",
      "weighted avg       0.94      0.94      0.94        79\n",
      "\n",
      "\tTraining Accuracy = 1.0\n",
      "\tTesting Accuracy = 0.9367088607594937\n",
      "layers = (8, 8), learning rate = 0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96        58\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.94        79\n",
      "   macro avg       0.92      0.91      0.92        79\n",
      "weighted avg       0.94      0.94      0.94        79\n",
      "\n",
      "\tTraining Accuracy = 1.0\n",
      "\tTesting Accuracy = 0.9367088607594937\n",
      "layers = (64, 64), learning rate = 0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95        58\n",
      "           1       0.94      0.76      0.84        21\n",
      "\n",
      "    accuracy                           0.92        79\n",
      "   macro avg       0.93      0.87      0.90        79\n",
      "weighted avg       0.93      0.92      0.92        79\n",
      "\n",
      "\tTraining Accuracy = 1.0\n",
      "\tTesting Accuracy = 0.9240506329113924\n",
      "layers = (8, 8, 8), learning rate = 0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97        58\n",
      "           1       0.95      0.86      0.90        21\n",
      "\n",
      "    accuracy                           0.95        79\n",
      "   macro avg       0.95      0.92      0.93        79\n",
      "weighted avg       0.95      0.95      0.95        79\n",
      "\n",
      "\tTraining Accuracy = 0.9683544303797469\n",
      "\tTesting Accuracy = 0.9493670886075949\n",
      "layers = (64, 64, 8), learning rate = 0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94        58\n",
      "           1       0.94      0.71      0.81        21\n",
      "\n",
      "    accuracy                           0.91        79\n",
      "   macro avg       0.92      0.85      0.88        79\n",
      "weighted avg       0.91      0.91      0.91        79\n",
      "\n",
      "\tTraining Accuracy = 1.0\n",
      "\tTesting Accuracy = 0.9113924050632911\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# mlp = MLPClassifier(hidden_layer_sizes=(8,8,8), solver='lbfgs', max_iter=1000)\n",
    "# mlp.fit(X_train, y_train)\n",
    "\n",
    "# print(f\"\\tTraining Accuracy = {mlp.score(X_train, y_train)}\")\n",
    "# print(f\"\\tTesting Accuracy = {mlp.score(X_test, y_test)}\")\n",
    "test(X_train, X_test, y_train, y_test, (2), .1)\n",
    "test(X_train, X_test, y_train, y_test, (8), .1)\n",
    "test(X_train, X_test, y_train, y_test, (8,8), .1)\n",
    "test(X_train, X_test, y_train, y_test, (64,64), .1)\n",
    "test(X_train, X_test, y_train, y_test, (8,8,8), .1)\n",
    "test(X_train, X_test, y_train, y_test, (64,64,8), .1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
