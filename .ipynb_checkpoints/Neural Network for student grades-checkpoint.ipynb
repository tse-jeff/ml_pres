{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4fca1c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1a8e45f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/dipam7/student-grade-prediction\n",
    "# P. Cortez and A. Silva. Using Data Mining to Predict Secondary School Student Performance. In A. Brito and J. Teixeira Eds., Proceedings of 5th FUture BUsiness TEChnology Conference (FUBUTEC 2008) pp. 5-12, Porto, Portugal, April, 2008, EUROSIS, ISBN 978-9077381-39-7.\n",
    "df = pd.read_csv('./student-mat.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b426cc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['school','address','Mjob','Fjob','reason'], inplace=True)\n",
    "for i in df.index:\n",
    "    df.loc[i,\"sex\"] = 0 if df.loc[i,\"sex\"] == \"F\" else 1\n",
    "    df.loc[i,\"famsize\"] = 0 if df.loc[i,\"famsize\"] == 'LT3' else 1\n",
    "    df.loc[i,'Pstatus'] = 0 if df.loc[i,'Pstatus'] == 'A' else 1\n",
    "    df.loc[i,'guardian'] = 0 if df.loc[i,'guardian'] == 'mother' else 1 if df.loc[i,'guardian'] == 'father' else 2\n",
    "    df.loc[i,\"schoolsup\"] = 0 if df.loc[i,\"schoolsup\"] == 'no' else 1\n",
    "    df.loc[i,\"famsup\"] = 0 if df.loc[i,\"famsup\"] == 'no' else 1\n",
    "    df.loc[i,\"paid\"] = 0 if df.loc[i,\"paid\"] == 'no' else 1\n",
    "    df.loc[i,\"activities\"] = 0 if df.loc[i,\"activities\"] == 'no' else 1\n",
    "    df.loc[i,\"nursery\"] = 0 if df.loc[i,\"nursery\"] == 'no' else 1\n",
    "    df.loc[i,\"higher\"] = 0 if df.loc[i,\"higher\"] == 'no' else 1\n",
    "    df.loc[i,\"internet\"] = 0 if df.loc[i,\"internet\"] == 'no' else 1\n",
    "    df.loc[i,\"romantic\"] = 0 if df.loc[i,\"romantic\"] == 'no' else 1\n",
    "# df = pd.get_dummies(df)\n",
    "\n",
    "out = np.where(df['G3'] > 13, 1, 0) # greater than 65% is passing\n",
    "inp = df.drop(['G3'], axis=1)\n",
    "\n",
    "# print(df.shape)\n",
    "# print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "146f4b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(X_train, X_test, y_train, y_test, layers, learning_rate):\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=layers, solver=\"lbfgs\",\n",
    "                        learning_rate_init=learning_rate, max_iter=1000)\n",
    "    mlp.fit(X_train, y_train)\n",
    "    y_pred = mlp.predict(X_test)\n",
    "    \n",
    "    print(f\"layers = {layers}, learning rate = {learning_rate}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"\\tTraining Accuracy = {mlp.score(X_train, y_train)}\")\n",
    "    print(f\"\\tTesting Accuracy = {mlp.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "95825d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers = (8, 8, 8), learning rate = 0.001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95        58\n",
      "           1       0.94      0.76      0.84        21\n",
      "\n",
      "    accuracy                           0.92        79\n",
      "   macro avg       0.93      0.87      0.90        79\n",
      "weighted avg       0.93      0.92      0.92        79\n",
      "\n",
      "\tTraining Accuracy = 1.0\n",
      "\tTesting Accuracy = 0.9240506329113924\n",
      "layers = (8, 8, 8), learning rate = 0.01\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        58\n",
      "           1       0.82      0.86      0.84        21\n",
      "\n",
      "    accuracy                           0.91        79\n",
      "   macro avg       0.88      0.89      0.89        79\n",
      "weighted avg       0.91      0.91      0.91        79\n",
      "\n",
      "\tTraining Accuracy = 1.0\n",
      "\tTesting Accuracy = 0.9113924050632911\n",
      "layers = (8, 8, 8), learning rate = 0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        58\n",
      "           1       1.00      0.71      0.83        21\n",
      "\n",
      "    accuracy                           0.92        79\n",
      "   macro avg       0.95      0.86      0.89        79\n",
      "weighted avg       0.93      0.92      0.92        79\n",
      "\n",
      "\tTraining Accuracy = 0.9841772151898734\n",
      "\tTesting Accuracy = 0.9240506329113924\n",
      "layers = (8, 8, 8), learning rate = 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95        58\n",
      "           1       0.94      0.76      0.84        21\n",
      "\n",
      "    accuracy                           0.92        79\n",
      "   macro avg       0.93      0.87      0.90        79\n",
      "weighted avg       0.93      0.92      0.92        79\n",
      "\n",
      "\tTraining Accuracy = 1.0\n",
      "\tTesting Accuracy = 0.9240506329113924\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(inp, out, test_size=.2)\n",
    "\n",
    "test(X_train, X_test, y_train, y_test, (8,8,8), .001)\n",
    "test(X_train, X_test, y_train, y_test, (8,8,8), .01)\n",
    "test(X_train, X_test, y_train, y_test, (8,8,8), .1)\n",
    "test(X_train, X_test, y_train, y_test, (8,8,8), 1)\n",
    "\n",
    "# train_sizes, train_scores, test_scores, fit_times, score_times = learning_curve(\n",
    "#     MLPClassifier((8,8,8), max_iter=1000), X_train, y_train, cv=5, return_times=True)\n",
    "# plt.scatter(fit_times, test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0896cb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jtse0\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers = 2, learning rate = 0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92        58\n",
      "           1       0.83      0.71      0.77        21\n",
      "\n",
      "    accuracy                           0.89        79\n",
      "   macro avg       0.87      0.83      0.85        79\n",
      "weighted avg       0.88      0.89      0.88        79\n",
      "\n",
      "\tTraining Accuracy = 0.9841772151898734\n",
      "\tTesting Accuracy = 0.8860759493670886\n",
      "layers = 8, learning rate = 0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96        58\n",
      "           1       0.94      0.81      0.87        21\n",
      "\n",
      "    accuracy                           0.94        79\n",
      "   macro avg       0.94      0.90      0.91        79\n",
      "weighted avg       0.94      0.94      0.94        79\n",
      "\n",
      "\tTraining Accuracy = 1.0\n",
      "\tTesting Accuracy = 0.9367088607594937\n",
      "layers = (8, 8), learning rate = 0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96        58\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.94        79\n",
      "   macro avg       0.92      0.91      0.92        79\n",
      "weighted avg       0.94      0.94      0.94        79\n",
      "\n",
      "\tTraining Accuracy = 1.0\n",
      "\tTesting Accuracy = 0.9367088607594937\n",
      "layers = (64, 64), learning rate = 0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95        58\n",
      "           1       0.94      0.76      0.84        21\n",
      "\n",
      "    accuracy                           0.92        79\n",
      "   macro avg       0.93      0.87      0.90        79\n",
      "weighted avg       0.93      0.92      0.92        79\n",
      "\n",
      "\tTraining Accuracy = 1.0\n",
      "\tTesting Accuracy = 0.9240506329113924\n",
      "layers = (8, 8, 8), learning rate = 0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97        58\n",
      "           1       0.95      0.86      0.90        21\n",
      "\n",
      "    accuracy                           0.95        79\n",
      "   macro avg       0.95      0.92      0.93        79\n",
      "weighted avg       0.95      0.95      0.95        79\n",
      "\n",
      "\tTraining Accuracy = 0.9683544303797469\n",
      "\tTesting Accuracy = 0.9493670886075949\n",
      "layers = (64, 64, 8), learning rate = 0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94        58\n",
      "           1       0.94      0.71      0.81        21\n",
      "\n",
      "    accuracy                           0.91        79\n",
      "   macro avg       0.92      0.85      0.88        79\n",
      "weighted avg       0.91      0.91      0.91        79\n",
      "\n",
      "\tTraining Accuracy = 1.0\n",
      "\tTesting Accuracy = 0.9113924050632911\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# mlp = MLPClassifier(hidden_layer_sizes=(8,8,8), solver='lbfgs', max_iter=1000)\n",
    "# mlp.fit(X_train, y_train)\n",
    "\n",
    "# print(f\"\\tTraining Accuracy = {mlp.score(X_train, y_train)}\")\n",
    "# print(f\"\\tTesting Accuracy = {mlp.score(X_test, y_test)}\")\n",
    "test(X_train, X_test, y_train, y_test, (2), .1)\n",
    "test(X_train, X_test, y_train, y_test, (8), .1)\n",
    "test(X_train, X_test, y_train, y_test, (8,8), .1)\n",
    "test(X_train, X_test, y_train, y_test, (64,64), .1)\n",
    "test(X_train, X_test, y_train, y_test, (8,8,8), .1)\n",
    "test(X_train, X_test, y_train, y_test, (64,64,8), .1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
